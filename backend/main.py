from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv

load_dotenv()

from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema.runnable import RunnableLambda
from langchain.callbacks import get_openai_callback

app = FastAPI()

api_key = os.getenv("API_KEY")
os.environ["OPENAI_API_KEY"] = api_key

origins = [
    "http://localhost:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# pdf íŒŒì¼ ë¡œë“œ
loader = PyMuPDFLoader("./test.pdf")
documents = loader.load()

# ë¬¸ì„œ ë¶„í•  
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    separator="\n\n",
    chunk_size=3000,
    chunk_overlap=500,
)

split_docs = text_splitter.split_documents(documents)

# Map ë‹¨ê³„
map_template = """ë‹¤ìŒì€ ë¬¸ì„œ ì¤‘ ì¼ë¶€ ë‚´ìš©ì…ë‹ˆë‹¤:
{page_content}
ì´ ë¬¸ì„œ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ì£¼ìš” ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”.
ë‹µë³€:"""
map_prompt = PromptTemplate.from_template(map_template)

llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0)

def extract_content(response):
    return response.content

map_chain = (map_prompt | llm | RunnableLambda(extract_content))

# Reduce ë‹¨ê³„
reduce_template = """ë‹¤ìŒì€ ìš”ì•½ì˜ ì§‘í•©ì…ë‹ˆë‹¤:
{doc_summaries}
ì´ê²ƒë“¤ì„ ë°”íƒ•ìœ¼ë¡œ í†µí•©ëœ ìš”ì•½ì„ ë§Œë“¤ì–´ ê·¸ê±¸ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì½ê³  ê³µë¶€ ë‚´ìš©ì„ í•™ìŠµí•  í•™ìŠµìš© ì†Œì„¤ì„ ì¨ì£¼ì„¸ìš”.
ë‹µë³€:"""
reduce_prompt = PromptTemplate.from_template(reduce_template)

reduce_chain = (reduce_prompt | llm | RunnableLambda(extract_content))

# Map-Reduce
def map_reduce(documents):
    with get_openai_callback() as cb:
        # Map ë‹¨ê³„: ê° í˜ì´ì§€ ìš”ì•½
        summaries = [map_chain.invoke({"page_content": doc.page_content[:500]}) for doc in documents]
        
        # Reduce ë‹¨ê³„: ê° í˜ì´ì§€ í•©ì³ì„œ ìµœì¢… ìš”ì•½
        final_summary = reduce_chain.invoke({"doc_summaries": "\n\n".join(summaries)})
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥
        print(f"ğŸ”¹ ì´ ìš”ì²­ í† í°: {cb.prompt_tokens}, ì´ ì‘ë‹µ í† í°: {cb.completion_tokens}, ì´ ì‚¬ìš© í† í°: {cb.total_tokens}")
    
    return final_summary

summary = map_reduce(documents)
print(summary)

@app.get("/")
def show_novel():
    return {"summary": summary}