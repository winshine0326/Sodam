from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import os
from dotenv import load_dotenv

load_dotenv()

from langchain_community.document_loaders import PyMuPDFLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema.runnable import RunnableLambda
from langchain.callbacks import get_openai_callback

app = FastAPI()

api_key = os.getenv("API_KEY")
os.environ["OPENAI_API_KEY"] = api_key

origins = [
    "http://localhost:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# pdf íŒŒì¼ ë¡œë“œ
loader = PyMuPDFLoader("./test.pdf")
documents = loader.load()

# ë¬¸ì„œ ë¶„í•  
text_splitter = CharacterTextSplitter.from_tiktoken_encoder(
    separator="\n\n",
    chunk_size=4000,
    chunk_overlap=500,
)

split_docs = text_splitter.split_documents(documents)

# Map ë‹¨ê³„
map_template = """ë‹¤ìŒ ë¬¸ì„œë¥¼ 200ì ì´ë‚´ë¡œ ìš”ì•½í•˜ì„¸ìš”:
{page_content}
ìš”ì•½:"""
map_prompt = PromptTemplate.from_template(map_template)

llm = ChatOpenAI(model_name="gpt-3.5-turbo-1106", temperature=0)

def extract_content(response):
    return response.content

map_chain = (map_prompt | llm | RunnableLambda(extract_content))

# Reduce ë‹¨ê³„
reduce_template = """ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì†Œì„¤ì„ 1000ì ì´ë‚´ë¡œ ë§Œë“œì„¸ìš”:
{doc_summaries}
ì†Œì„¤:"""
reduce_prompt = PromptTemplate.from_template(reduce_template)

reduce_chain = (reduce_prompt | llm | RunnableLambda(extract_content))

# Map-Reduce
def map_reduce(documents):
    with get_openai_callback() as cb:
        # Map ë‹¨ê³„: ê° í˜ì´ì§€ ìš”ì•½
        summaries = [map_chain.invoke({"page_content": doc.page_content[:500]}) for doc in documents]
        
        # Reduce ë‹¨ê³„: ë°”ë¡œ ì†Œì„¤ ìƒì„±
        final_summary = reduce_chain.invoke({"doc_summaries": "\n\n".join(summaries)})
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶œë ¥
        print(f"ğŸ”¹ ì´ ìš”ì²­ í† í°: {cb.prompt_tokens}, ì´ ì‘ë‹µ í† í°: {cb.completion_tokens}, ì´ ì‚¬ìš© í† í°: {cb.total_tokens}")
    
    return final_summary

summary = map_reduce(documents)
print(summary)

@app.get("/")
def show_novel():
    return {"summary": summary}
